{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270195fa",
   "metadata": {},
   "source": [
    "# <center> <b> <span style=\"color:orange;\">              Module NLTK                     </span> </b></center>\n",
    "\n",
    "\n",
    "\n",
    "# <center> <b> <span style=\"color:orange;\">        Presenté par HAIDARA Ababacar                     </span> </b></center>\n",
    "\n",
    "\n",
    "### <center>  <b> <span style=\"color:brown;\">          Introduction au Natural Language Toolkit (NLTK)               </span> </b></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "L'analyse naturelle du langage (NLP: Natural Language Processing) provient d'un processus automatique ou semi-automatique du langage humain. Le NLP fut développé autour de la recherche linguistique et des sciences cognitives, la psychologie, la biologie et les mathématiques. Dans le domaine particulier de l'informatique, la NLP est rattachée aux techniques de compilation, au théorie formelle du langage, à l'intéraction homme-machine, au \"machine learning\" et à la preuve par le théorême. \n",
    "\n",
    "Les interactions entre humains et machines sont longtemps passées par des claviers et du code informatique. Et il était possible de communiquer avec un ordinateur uniquement par écrit ou à l’oral en langage naturel, comme on le ferait avec un autre humain ? Tel est le but du Natural Language Processing.\n",
    "\n",
    "### <left> <b> <span style=\"color:brown;\"> 1. Qu'est-ce que c'est NLTK ? </span> </b></left>\n",
    "Natural Language Toolkit (NLTK) est une boîte-à-outil permettant la création de programmes pour l'analyse de texte. Cet ensemble a été créé à l'origine par Steven Bird et Edward Loper, en relation avec des cours de linguistique informatique à l'Université de Pennsylvanie en 2001.\n",
    "\n",
    "Le traitement naturel du langage, aussi appelé Natural Language Processing ou NLP, est une branche de l’intelligence artificielle. Elle vise à permettre aux humains d’interagir avec les ordinateurs par le langage naturel.\n",
    "Grâce à cette technologie, les machines deviendront à terme capables de déchiffrer et de comprendre le langage humain. Afin de parvenir à ce but, différents modèles, techniques et autres bibliothèques de langage de programmation ont été développés.\n",
    "\n",
    "Le NLTK, ou Natural Language Toolkit, est une suite de bibliothèques logicielles et de programmes. Elle est conçue pour le traitement naturel symbolique et statistique du langage anglais en langage Python. C’est l’une des bibliothèques de traitement naturel du langage les plus puissantes.\n",
    "\n",
    "\n",
    "### <left> <b> <span style=\"color:brown;\"> 2. A quoi sert le NLP ?</span> </b></left>\n",
    "Chaque jour, les pages web, les blogs et les réseaux sociaux génèrent d’immenses quantités de données sous forme de texte. En analysant ces données, les entreprises peuvent comprendre les internautes et leurs centres d’intérêt afin de développer de nouveaux services et produits.\n",
    "\n",
    "Le Traitement Naturel du Langage est utilisé de nombreuses manières. Les moteurs de recherche comme Google et Yahoo reposent sur cette technologie pour comprendre le sens des recherches sur le web.\n",
    "\n",
    "Les réseaux sociaux comme Facebook analysent les centres d’intérêt des utilisateurs pour leur proposer des publicités ciblées ou présenter du contenu pertinent dans leur flux d’actualité. \n",
    "\n",
    "Cette suite d’outils rassemble les algorithmes les plus communs du traitement naturel du langage comme le tokenizing, le part-of-speech tagging, le stemming, l’analyse de sentiment, la segmentation de topic ou la reconnaissance d’entité nommée.\n",
    "\n",
    "### <left> <b> <span style=\"color:brown;\"> 3. Quelques algorithmes de NLTK </span> </b></left>\n",
    "La tokenization est un processus permettant de réduire  diviser un texte en plusieurs sous-parties appelées tokens. Cette méthode permet d’extraire des statistiques depuis le corpus de texte, par exemple le nombre de phrases.\n",
    "\n",
    "La méthode du Stemming permet de convertir un ensemble de mots dans une phrase en une séquence, Les mots ayant le même sens, mais varient en fonction du contexte sont ainsi normalisée. Le but est de trouver la racine à partir des différentes variations du mot. Le NLTK regroupe plusieurs ” stemmers ” comme le Porter Stemmer, le Snowball Stemmer et le Lancaster Stemmer.\n",
    "\n",
    "La technique de Lemmatisation est un processus algorithmique permettant de trouver le lemme d’un mot en fonction de son sens. Il s’agit de l’analyse morphologique des mots, visant à supprimer ses affixes. Sur NTLK, la fonction morph native de WordNet est utilisée pour la Lemmatisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa02299",
   "metadata": {},
   "source": [
    "### <left> <b> <span style=\"color:brown;\"> Travailler avec NLTK </span> </b></left>\n",
    "La première chose à faire pour utiliser NLTK est de télécharger ce qui se nomme le NLTK corpora. Je vais télécharger tout le Corpus. Je sais qu'il est énorme (10,9 Go), mais nous ne le ferons qu'une seule fois. Si vous connaissez déjà quel corpus vous utiliserez, inutile de télécharger cet ensemble.\n",
    "\n",
    "Un corpus est un ensemble de documents, artistiques ou non (textes, images, vidéos, etc.), regroupés dans une optique précise.\n",
    "\n",
    "Dans votre éditeur Python, écrivez ceci :\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c8df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "  import nltk\n",
    "    \n",
    "  nltk.download()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10f55c",
   "metadata": {},
   "source": [
    "##Dans ce cas précis, une interface graphique s'affiche, vous permettant de définir la destination des fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029204f",
   "metadata": {},
   "source": [
    "# De quoi ressemble tout ce qu'on a dit ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importons les librairies qui nous seront nécessaire:\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc96dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = u\"\"\"Wikipédia est un projet wiki d’encyclopédie collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki. \n",
    "Aimez-vous l'encyclopédie wikipedia ?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef289f",
   "metadata": {},
   "source": [
    "# Les « stops words »\n",
    "\n",
    "Il faudra retirer tous les mots qui n’apportent pas vraiment de valeurs à l’analyse globale du texte. On appelle ces mots les « stop words » et bien sur cette liste est propre à chaque langue. Bonne nouvelle, NLTK propose une liste de stop words en Français (toutes les langues ne sont en effet pas disponibles) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = set(stopwords.words('french'))\n",
    "filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea816a5",
   "metadata": {},
   "source": [
    "Grâce à la fonction lambda de Python on créé une petite fonction qui nous permettra \n",
    "en une seule ligne de filtrer un texte à partir de la liste des stop words français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = set(stopwords.words(‘french’)) filtre_stopfr = lambda text: [token for token in text if token.lower() not in french_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre_stopfr( word_tokenize(data, language=\"french\") )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "['Wikipédia',\n",
    " 'projet',\n",
    " 'wiki',\n",
    " '’',\n",
    " 'encyclopédie',\n",
    " 'collective',\n",
    " 'ligne',\n",
    " ',',\n",
    " 'universelle',\n",
    " ',',\n",
    " 'multilingue',\n",
    " 'fonctionnant',\n",
    " 'principe',\n",
    " 'wiki',\n",
    " '.',\n",
    " 'Aimez-vous',\n",
    " \"l'encyclopédie\",\n",
    " 'wikipedia',\n",
    " '?']\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c217e20",
   "metadata": {},
   "source": [
    "# Tokenisation\n",
    "Avec NLTK on peut découper par mot avec la fonction word_tokenize(…) ou par phrase sent_tokenize(…). Commençons par un découpage par phrase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659df149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sent_tokenize(data, language=\"french\")\n",
    "\n",
    "\"\"\"\n",
    "['Wikipédia est un projet wiki d’encyclopédie collective en ligne, universelle, multilingue et fonctionnant sur le principe du wiki.',\n",
    " \"Aimez-vous l'encyclopédie wikipedia ?\"]\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7aff0",
   "metadata": {},
   "source": [
    "Intéressant mais la tokenization par mot l’est encore plus bien sur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(data, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['Wikipédia',\n",
    " 'est',\n",
    " 'un',\n",
    " 'projet',\n",
    " 'wiki',\n",
    " 'd',\n",
    "...\n",
    " 'Aimez-vous',\n",
    " \"l'encyclopédie\",\n",
    " 'wikipedia',\n",
    " '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5ac3a",
   "metadata": {},
   "source": [
    "# Stemmatisation\n",
    "Maintenant il serait interressant de regrouper les mots ayant la même racine synthaxique, pour cela nous allons utiliser la fonction de stemmatisation de NLTK : stem(). Bonne nouvelle encore il existe une fonction pour le français FrenchStemmer() ! nous allons bien sur l’utiliser ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_words = [\"donner\",\"don\",\"donne\",\"donnera\",\"dons\",\"test\"]\n",
    "stemmer = FrenchStemmer()\n",
    " \n",
    "for w in example_words:\n",
    "    print(stemmer.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b97fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "don\n",
    "dondon\n",
    "don\n",
    "don\n",
    "don\n",
    "don\n",
    "test\n",
    "don\n",
    "don\n",
    "don\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02d91e",
   "metadata": {},
   "source": [
    "### <center>  <b> <span style=\"color:brown;\">          Conclusion               </span> </b></center>\n",
    "\n",
    "\n",
    "\n",
    "L’objectif de cet exposé étant de montrer les fonctionnalités de base de NLTK nous ne sommes pas entré dans le détail. Cette librairie est riche, très riche même mais nécessite pas mal d’ajustement si vous voulez créer des fonctions à base de NLP puissante.\n",
    "\n",
    "Malgré les avancées menées par la recherche, les systèmes de langage naturel qui ont été déployés pour des applications du monde réel ne peuvent toujours pas effectuer un raisonnement de bon sens ou tirer parti des connaissances mondiales de manière générale et robuste. Nous pouvons attendre que ces problèmes difficiles d'intelligence artificielle soient résolus, mais en attendant, il est nécessaire de vivre avec de sévères limitations sur les capacités de raisonnement et de connaissance des systèmes de langage naturel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3303fe",
   "metadata": {},
   "source": [
    "### <center>  <b> <span style=\"color:brown;\"> Bibliographie </span> </b></center>\n",
    "\n",
    "\n",
    "\n",
    "https://www.datacorner.fr/nltk/\n",
    "    \n",
    "https://datascientest.com/nltk\n",
    "\n",
    "http://www.nltk.org/book/ch01.html\n",
    "https://code.tutsplus.com/fr/tutorials/introducing-the-natural-language-toolkit-nltk--cms-28620\n",
    "\n",
    "https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/\n",
    "\n",
    "https://www.nltk.org/_modules/nltk/data.html#SeekableUnicodeStreamReader.discard_line\n",
    "    \n",
    "https://www.nltk.org/api/nltk.html#module-nltk.__init__\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
